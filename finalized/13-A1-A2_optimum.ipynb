{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb0ee85-ef44-43dc-a363-a335725dfed7",
   "metadata": {},
   "source": [
    "# Finding optimal values for A1 and A2 coefficient\n",
    "\n",
    "Given an \"ideal\" initial snow density, we try to determine what is the best pair of (A1, A2) coefficients, using 3 different metrics (see Notebook 19).\n",
    "\n",
    "**WARNING: THE OPTIMIZATION MAY DEPEND ON THE OFFSET VALUE > PERHAPS A GRAPH MAY BE HELPFUL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9385cc-7215-43c9-a7cb-45bf18ebefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO re-write the top part (and title?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b040b0-70f9-4cb0-8063-c590e157183d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506f73f8-863a-4a04-91ad-02af45eadda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "from scipy.stats import sem\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551e280c-77f6-40a2-9d5b-cd88d07e0e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_met_forcing() - Warning: check the format of your file corresponds to the indices given in the functions (wind speed 5, surface temperature 8, time 0).\n"
     ]
    }
   ],
   "source": [
    "%run little_awk_functions.py\n",
    "%run parameters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7bd5966-ac10-42ce-99d9-4adfed9652b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_simulation(data_set_used, x_sel, y_sel, data_duration_in_s, ds_time_indices, end_accumulation_times, end_erosion_times, start_accumulation, end_accumulation, \n",
    "                      start_erosion, end_erosion, jj, dt, ro_layer, ro_water, ro_ice, t_old, tf, tsfc, dy_snow, age_layers, gamma, cp_snow, melt_flag, a1, a2,\n",
    "                      met_temp, met_time, simul_new_snow_ro, simul_fit_top_of_snowfall_to_curve):\n",
    "    '''\n",
    "    Function that uses the simulate_snowpack_evolution() function to simulate the snowpack's evolution for a given (a1, a2) pair\n",
    "    Args:\n",
    "        data_duration_in_s: total duration of the lidar data, in seconds\n",
    "        ds_time_indices: indices of the simulation that correspond to the lidar data (and should thus be the only to be kept)\n",
    "        for all other arguments, please refer to the simulate_snowpack_evolution() docstring\n",
    "    Returns:\n",
    "        an np-array containing:\n",
    "        a1, a2: unchanged values, used for identification of the results\n",
    "        total_snow_depth: array containing the depth of the snowpack at each timestamp\n",
    "    '''\n",
    "    nb_iterations = int(data_duration_in_s/dt + 1)\n",
    "\n",
    "    # Update variables at each timepoint\n",
    "\n",
    "    snowpack = simulate_snowpack_evolution(data_set_used, x_sel, y_sel, nb_iterations, end_accumulation_times, end_erosion_times,\n",
    "                                       start_accumulation, end_accumulation, start_erosion, end_erosion, jj, dt, ro_layer, ro_water, ro_ice,\n",
    "                                       t_old, tf, tsfc, dy_snow, age_layers, gamma, cp_snow, melt_flag, a1, a2, met_temp_data=met_temp,\n",
    "                                       met_time_data=met_time, new_snow_ro=simul_new_snow_ro,\n",
    "                                       fit_top_of_snowfall_to_curve=simul_fit_top_of_snowfall_to_curve)\n",
    "\n",
    "    ro_layer_evolution, depth_evolution, temperature_evolution = snowpack[0], snowpack[1], snowpack[2]\n",
    "     \n",
    "    # Define total_snow_depth\n",
    "    \n",
    "    # simulation_times = pd.date_range(start=data_start_date,freq=str(dt)+'S',periods=nb_iterations)\n",
    "    total_snow_depth = np.array([sum(depth_evolution[i][j] for j in range(max_nb_of_layers)) for i in range(len(depth_evolution)) if i in ds_time_indices])\n",
    "    \n",
    "    return(np.array([a1, a2, total_snow_depth], dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f0370e-9250-40c5-a2ec-36c5e0b962c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_simulation(data_set_used, x_sel, y_sel, data_duration_in_s, ds_time_indices, end_accumulation_times, end_erosion_times, start_accumulation, end_accumulation, \n",
    "                      start_erosion, end_erosion, jj, dt, ro_layer, ro_water, ro_ice, t_old, tf, tsfc, dy_snow, age_layers, gamma, cp_snow, melt_flag, a1_range, a2_range,\n",
    "                      met_temp, met_time, simul_new_snow_ro, simul_fit_top_of_snowfall_to_curve):\n",
    "    '''\n",
    "    Function that runs single_simulation() in parallel for a range of values of a1 and a2\n",
    "    Args:\n",
    "        data_duration_in_s: total duration of the lidar data, in seconds\n",
    "        ds_time_indices: indices of the simulation that correspond to the lidar data (and should thus be the only to be kept)\n",
    "        for all other arguments, please refer to the simulate_snowpack_evolution() docstring\n",
    "    Returns:\n",
    "        p_s: array containing the [a1, a2, total_snow_depth] results computed for each pair of (a1, a2) arguments\n",
    "    '''\n",
    "    a1_a2_range = [(a1, a2) for a1 in a1_range for a2 in a2_range]\n",
    "    \n",
    "    p_s = Parallel(n_jobs=-2)(delayed(single_simulation)(data_set_used, x_sel, y_sel, data_duration_in_s, ds_time_indices, end_accumulation_times, end_erosion_times,\n",
    "                      start_accumulation, end_accumulation, start_erosion, end_erosion, jj, dt, ro_layer, ro_water, ro_ice, t_old, tf, tsfc, dy_snow, age_layers, gamma, cp_snow,\n",
    "                      melt_flag, a1, a2, met_temp, met_time, simul_new_snow_ro, simul_fit_top_of_snowfall_to_curve) for (a1, a2) in a1_a2_range)\n",
    "    \n",
    "    return(np.array(p_s, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf44304f-b95d-4d88-bfdb-2697b6812d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lidar timepoints to match simulation times > see first metrics functions\n",
    "\n",
    "def parallel_measures(parallel_simulations_array, lidar_height_array):\n",
    "    '''\n",
    "    Function that runs all_measures() in parallel for a range of values of a1 and a2\n",
    "    Args:\n",
    "        parallel_simulations_array: array containing the [a1, a2, total_snow_depth] results of simulations computed for each pair of (a1, a2) arguments\n",
    "        lidar_height_array: array containing the depth of the snowpack as measured by the lidar, corresponding to each simulation timestamp\n",
    "    Returns:\n",
    "        p_m: array containing the [a1, a2, (rmse, stde, p_corr)] measure results computed for each pair of (a1, a2) arguments\n",
    "    '''\n",
    "    p_m = Parallel(n_jobs=-2)(delayed(all_measures)(parallel_simulations_array[i][0], parallel_simulations_array[i][1], parallel_simulations_array[i][2], lidar_height_array)  # a1, a2, simul_total_height_array\n",
    "                       for i in range(len(parallel_simulations_array)))\n",
    "    \n",
    "    return(p_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06516cc-95cb-4c95-9dee-f0e339a43fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add all those functions to little_awk_functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9985f98-fe3b-4862-a05f-27d3edd4a315",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a4c1f1a-046d-4f2a-8122-d479a4226d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "name_of_data_set = 'snow_pit_1_filled.nc'\n",
    "\n",
    "save_figures = False\n",
    "save_text_results = False\n",
    "\n",
    "directory_to_save_figs_in = '/home/mabonnet/github/MB_little_awk/current_development/A1_A2_optimum/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a4c4e03-f7a8-4323-b7e2-a4882acfaf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events detection parameters\n",
    "\n",
    "x_sel = 10\n",
    "y_sel = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d0dd5d9-02f2-45b7-bac5-ca5480b583fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compaction/temperature model parameters\n",
    "\n",
    "tsfc = -5\n",
    "cp_snow = 2106\n",
    "dt = 100\n",
    "a1 = 0.0013\n",
    "a2 = 0.021\n",
    "\n",
    "use_true_temp = False   # set to True if want to use the correct temperature forcing\n",
    "\n",
    "# TODO add ice layer detection option > not yet\n",
    "\n",
    "# Will not be varied for now\n",
    "\n",
    "max_nb_of_layers = 25\n",
    "simul_fit_top_of_snowfall_to_curve = False\n",
    "tf = 0\n",
    "ro_water = 1000\n",
    "ro_ice = 910\n",
    "jj = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9097ab24-8c38-4b7f-8160-2bfb6e4b10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_range = np.linspace(0.001, 0.005, num=15, endpoint=True)\n",
    "a2_range = np.linspace(0.02, 0.04, num=10, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2931bee8-b099-43cc-81ad-931095b742ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0012857142857142859, 0.022222222222222223), (0.004714285714285714, 0.03777777777777778), (0.004714285714285714, 0.022222222222222223), (0.0012857142857142859, 0.03777777777777778), (0.003, 0.03777777777777778)]\n"
     ]
    }
   ],
   "source": [
    "# Couples of values to plot the lidar graph of\n",
    "\n",
    "couples_to_plot = [(a1_range[1], a2_range[1]), (a1_range[-2], a2_range[-2]), (a1_range[-2], a2_range[1]), (a1_range[1], a2_range[-2]), (a1_range[7], a2_range[8])]\n",
    "print(couples_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c4119-b170-4eec-8495-370d4b086424",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean dataset and derive other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28005abe-6bfd-418d-8b73-c9b4d2fda05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Median filtering in space with a window [7, 11]\n",
      "---> Median filtering in time with a window of 11\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing to get clean data\n",
    "\n",
    "data_set_used = xr.open_dataset(name_of_data_set)\n",
    "\n",
    "data_set_used = data_set_used.ffill(dim='time')\n",
    "\n",
    "median_space_filtering(data_set_used, 5, x_span=7)\n",
    "median_time_filtering(data_set_used, 11)\n",
    "\n",
    "data_set_used['snow_surface'] = data_set_used['snow_surface'] - data_set_used['snow_surface'].isel(x=x_sel, y=y_sel).dropna('time').min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52e6346-7714-4024-bdf5-25ce1e8323e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dates\n",
    "\n",
    "data_starting_date_in_ns = float(data_set_used.time.values[0])\n",
    "\n",
    "data_starting_date_in_s = pd.to_datetime(data_set_used.time.values[0]).timestamp()\n",
    "data_ending_date_in_s = pd.to_datetime(data_set_used.time.values[-1]).timestamp()\n",
    "data_duration_in_s = data_ending_date_in_s - data_starting_date_in_s\n",
    "nb_iterations = int(data_duration_in_s/dt + 1)\n",
    "\n",
    "data_start_date = pd.to_datetime(data_set_used.time.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47056394-72b1-4c2c-a48a-9cd48ffd69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_snow_events(data_set_used, x_sel, y_sel, time_window_std, std_threshold)\n",
    "start_accumulation, start_erosion, end_accumulation, end_erosion = results[0], results[1], results[2], results[3]\n",
    "\n",
    "# Convert end times into more manageable orders of magnitude\n",
    "\n",
    "end_accumulation_times = data_set_used.snow_surface.isel(x=x_sel, y=y_sel, time=end_accumulation)\n",
    "end_accumulation_times = (pd.to_datetime(end_accumulation_times.time).astype(int) - data_starting_date_in_ns) / 1000000000  # in s\n",
    "\n",
    "end_erosion_times = data_set_used.snow_surface.isel(x=x_sel, y=y_sel, time=end_erosion)\n",
    "end_erosion_times = (pd.to_datetime(end_erosion_times.time).astype(int) - data_starting_date_in_ns) / 1000000000  # in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18e26035-520c-4f54-bc2b-ba183f904f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_height_array = []\n",
    "keep_simul_times_indices = []    # indices of the timestamps to keep in the simulation data, that are comparable to the lidar data\n",
    "                                # given that dt << lidar scans time period, there are no repetitions in keep_simul_times_indices\n",
    "ignore = np.isnan(data_set_used.snow_surface.isel(x=x_sel, y=y_sel))     # do not take into account the nan values in the dataset\n",
    "\n",
    "for index in range(len(data_set_used.time.values)):\n",
    "        lidar_time_in_s = float(data_set_used.time.values[index]) / 1000000000 - float(data_set_used.time.values[0]) / 1000000000\n",
    "        if lidar_time_in_s < nb_iterations*dt and not ignore[index]:\n",
    "            lidar_height_array.append(data_set_used.snow_surface.isel(x=x_sel, y=y_sel, time=index))\n",
    "\n",
    "            index_of_closest_time_in_simul = int(lidar_time_in_s//dt + round((lidar_time_in_s%dt)/dt))\n",
    "            keep_simul_times_indices.append(index_of_closest_time_in_simul)\n",
    "\n",
    "lidar_height_array = np.array(lidar_height_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bba38-ddf9-4f0c-9e51-f39d5253b20b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loop on parameters A1 and A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d22cc8e-8ecd-4e2e-9a25-ea49d87b84c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simul_new_snow_ro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m simul \u001b[38;5;241m=\u001b[39m parallel_simulation(data_set_used, x_sel, y_sel, data_duration_in_s, keep_simul_times_indices, end_accumulation_times, end_erosion_times, start_accumulation, end_accumulation, \n\u001b[1;32m      2\u001b[0m                       start_erosion, end_erosion, jj, dt, ro_layer, ro_water, ro_ice, t_old, tf, tsfc, dy_snow, age_layers, gamma, cp_snow, melt_flag, a1_range, a2_range,\n\u001b[0;32m----> 3\u001b[0m                       met_temp, met_time, \u001b[43msimul_new_snow_ro\u001b[49m, simul_fit_top_of_snowfall_to_curve)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simul_new_snow_ro' is not defined"
     ]
    }
   ],
   "source": [
    "simul = parallel_simulation(data_set_used, x_sel, y_sel, data_duration_in_s, keep_simul_times_indices, end_accumulation_times, end_erosion_times, start_accumulation, end_accumulation, \n",
    "                      start_erosion, end_erosion, jj, dt, ro_layer, ro_water, ro_ice, t_old, tf, tsfc, dy_snow, age_layers, gamma, cp_snow, melt_flag, a1_range, a2_range,\n",
    "                      met_temp, met_time, simul_new_snow_ro, simul_fit_top_of_snowfall_to_curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d67e6b-4fb3-471c-8080-70e49a5f6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "measrs = parallel_measures(simul, lidar_height_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85973088-de45-4bdb-876a-e6996f905886",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(measrs)):\n",
    "    if measrs[i][2][2] == max(measrs[i][2][2] for i in range(len(measrs))):\n",
    "        print('Pearson correlation max: ', measrs[i])\n",
    "    if measrs[i][2][1] == min(measrs[i][2][1] for i in range(len(measrs))):\n",
    "        print('Std error min: ', measrs[i])\n",
    "    if measrs[i][2][0] == min(measrs[i][2][0] for i in range(len(measrs))):\n",
    "        print('RMSE min: ', measrs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b53bf-3fb5-4c64-8057-ef0e5c94dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE measure > min is best\n",
    "\n",
    "x = a1_range\n",
    "y = a2_range\n",
    "z = np.array([measrs[i][2][0] for i in range(len(measrs))])\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = z.reshape(len(x), len(y)).T\n",
    "\n",
    "plt.pcolor(X, Y, Z)\n",
    "plt.xlabel('a1')\n",
    "plt.ylabel('a2')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f20406-d762-4a44-8449-6ccd976c915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std error measure > min is best\n",
    "\n",
    "x = a1_range\n",
    "y = a2_range\n",
    "z = np.array([measrs[i][2][1] for i in range(len(measrs))])\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = z.reshape(len(x), len(y)).T\n",
    "\n",
    "plt.pcolor(X, Y, Z)\n",
    "plt.xlabel('a1')\n",
    "plt.ylabel('a2')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ccca7-1282-4027-9977-26b7163d3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation measure > max is best\n",
    "\n",
    "x = a1_range\n",
    "y = a2_range\n",
    "z = np.array([measrs[i][2][2] for i in range(len(measrs))])\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = z.reshape(len(x), len(y)).T\n",
    "\n",
    "plt.pcolor(X, Y, Z)\n",
    "plt.xlabel('a1')\n",
    "plt.ylabel('a2')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f45809e-feb4-443e-9b26-f04aa9093e48",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0d134-0314-4e01-9223-9ca50b3b387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_step = a1_range[1]-a1_range[0]\n",
    "a2_step = a2_range[1]-a2_range[0]\n",
    "\n",
    "optimum_coords = [5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2bdeb-e5cb-433b-a073-95960558d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(7, 10))\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='a1', ylabel='a2')\n",
    "    # ax.set_xticks(a1_range * 1000, ['%d' % val for val in a1_range])\n",
    "    # ax.set_xticks(a1_range)# * 100) \n",
    "    # ax.set_xticklabels(['%d' % val for val in a1_range])\n",
    "    ax.label_outer()\n",
    "\n",
    "x = a1_range\n",
    "y = a2_range\n",
    "z_rmse = np.array([measrs[i][2][0] for i in range(len(measrs))])\n",
    "z_corr = np.array([measrs[i][2][2] for i in range(len(measrs))])\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z_rmse = z_rmse.reshape(len(x), len(y)).T\n",
    "Z_corr = z_corr.reshape(len(x), len(y)).T\n",
    "\n",
    "fig0 = axs[0].pcolor(X, Y, Z_rmse)\n",
    "axs[0].set_title('Root Mean Square Error')\n",
    "fig.colorbar(fig0, ax=axs[0])\n",
    "\n",
    "axs[0].add_patch(Rectangle((a1_range[1] - a1_step/2, a2_range[1] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))\n",
    "axs[0].add_patch(Rectangle((a1_range[-2] - a1_step/2, a2_range[-2] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))\n",
    "axs[0].add_patch(Rectangle((a1_range[-2] - a1_step/2, a2_range[1] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))\n",
    "axs[0].add_patch(Rectangle((a1_range[1] - a1_step/2, a2_range[-2] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))\n",
    "axs[0].add_patch(Rectangle((a1_range[optimum_coords[0]] - a1_step/2, a2_range[optimum_coords[1]] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))   # TODO last one should be modular\n",
    "\n",
    "fig1 = axs[1].pcolor(X, Y, Z_corr)\n",
    "axs[1].set_title('Pearson correlation')\n",
    "fig.colorbar(fig1, ax=axs[1])\n",
    "\n",
    "axs[1].add_patch(Rectangle((a1_range[1] - a1_step/2, a2_range[1] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))\n",
    "axs[1].add_patch(Rectangle((a1_range[-2] - a1_step/2, a2_range[-2] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))\n",
    "axs[1].add_patch(Rectangle((a1_range[-2] - a1_step/2, a2_range[1] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))\n",
    "axs[1].add_patch(Rectangle((a1_range[1] - a1_step/2, a2_range[-2] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))\n",
    "axs[1].add_patch(Rectangle((a1_range[optimum_coords[0]] - a1_step/2, a2_range[optimum_coords[1]] - a2_step/2), a1_step, a2_step, edgecolor='white', facecolor='none', lw=1, ls='-'))   # TODO last one should be modular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe3ff5-c5e8-41cd-b4ab-c7f071154d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimum_index = optimum_coords[0]*len(a2_range) + optimum_coords[1]\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(10, 10))\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='time', ylabel='snow height (m)')\n",
    "    ax.label_outer()\n",
    "\n",
    "axs[0].plot(simul[len(a2_range)+1][2], label='a1 = '+str(round(simul[len(a2_range)+1][0], 4))+', a2 = '+str(round(simul[len(a2_range)+1][1], 3)))\n",
    "axs[0].plot(data_set_used.snow_surface.isel(x=x_sel, y=y_sel), label='lidar data')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(simul[-2*len(a2_range)+(len(a2_range)-2)][2], label='a1 = '+str(round(simul[-2*len(a2_range)+(len(a2_range)-2)][0], 4))+', a2 = '+str(round(simul[-2*len(a2_range)+(len(a2_range)-2)][1], 3)))\n",
    "axs[1].plot(data_set_used.snow_surface.isel(x=x_sel, y=y_sel), label='lidar data')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(simul[len(a2_range)+(len(a2_range)-2)][2], label='a1 = '+str(round(simul[len(a2_range)+(len(a2_range)-2)][0], 4))+', a2 = '+str(round(simul[len(a2_range)+(len(a2_range)-2)][1], 3)))\n",
    "axs[2].plot(data_set_used.snow_surface.isel(x=x_sel, y=y_sel), label='lidar data')\n",
    "axs[2].legend()\n",
    "\n",
    "axs[3].plot(simul[-2*len(a2_range)+1][2], label='a1 = '+str(round(simul[-2*len(a2_range)+1][0], 4))+', a2 = '+str(round(simul[-2*len(a2_range)+1][1], 3)))\n",
    "axs[3].plot(data_set_used.snow_surface.isel(x=x_sel, y=y_sel), label='lidar data')\n",
    "axs[3].legend()\n",
    "\n",
    "axs[4].plot(simul[optimum_index][2], label='a1 = '+str(round(simul[optimum_index][0], 4))+', a2 = '+str(round(simul[optimum_index][1], 3)))\n",
    "axs[4].plot(data_set_used.snow_surface.isel(x=x_sel, y=y_sel), label='lidar data')\n",
    "axs[4].legend()\n",
    "\n",
    "fig.suptitle('Simulated vs measured snow height for different values of a1, a2')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78603a53-eb14-4b81-af66-f1157be2dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other option for presentation of results (change fig sizes, make first one horizontal for eg.)\n",
    "\n",
    "optimum_index = optimum_coords[0]*len(a2_range) + optimum_coords[1]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "fig.xlabel='time'\n",
    "fig.ylabel='snow height (m)'\n",
    "\n",
    "plt.plot(simul[len(a2_range)+1][2], label='a1 = '+str(round(simul[len(a2_range)+1][0], 4))+', a2 = '+str(round(simul[len(a2_range)+1][1], 3)))\n",
    "plt.plot(simul[-2*len(a2_range)+(len(a2_range)-2)][2], label='a1 = '+str(round(simul[-2*len(a2_range)+(len(a2_range)-2)][0], 4))+', a2 = '+str(round(simul[-2*len(a2_range)+(len(a2_range)-2)][1], 3)))\n",
    "plt.plot(simul[len(a2_range)+(len(a2_range)-2)][2], label='a1 = '+str(round(simul[len(a2_range)+(len(a2_range)-2)][0], 4))+', a2 = '+str(round(simul[len(a2_range)+(len(a2_range)-2)][1], 3)))\n",
    "plt.plot(simul[-2*len(a2_range)+1][2], label='a1 = '+str(round(simul[-2*len(a2_range)+1][0], 4))+', a2 = '+str(round(simul[-2*len(a2_range)+1][1], 3)))\n",
    "\n",
    "plt.plot(simul[optimum_index][2], label='a1 = '+str(round(simul[optimum_index][0], 4))+', a2 = '+str(round(simul[optimum_index][1], 3)))\n",
    "\n",
    "plt.plot(data_set_used.snow_surface.isel(x=x_sel, y=y_sel), label='lidar data')\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Simulated vs measured snow height for different values of a1, a2')\n",
    "\n",
    "# TODO adjust colors and alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459a42e-4ebb-4e3e-b3d0-e05c94ac76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find a way of identifying each couple-point to the corresponding graph > put numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104b8ef-c06c-4acc-b0c6-689cf859d319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awk",
   "language": "python",
   "name": "awk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
