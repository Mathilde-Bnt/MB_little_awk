{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a6fe6b-64f1-4abd-bbee-68fa94a8826a",
   "metadata": {},
   "source": [
    "# Reference snowpits\n",
    "\n",
    "This notebook aims at extracting and plotting the data obtained at each snowpit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0a996-5dd2-4a34-9471-589ce33a244f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d69a98-9bc8-4d82-8453-ad2dfc03fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be47d30-d360-498a-b403-3e6b893f5d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_met_forcing() - Warning: check the format of your file corresponds to the indices given in the functions (wind speed 5, surface temperature 7, time 0).\n"
     ]
    }
   ],
   "source": [
    "%run little_awk_functions.py\n",
    "%run parameters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27985a52-2792-497d-a244-1275b8337b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_new_snow_ro(nb_iterations, end_accumulation_times, start_accumulation, end_accumulation, dt, met_temp_data=[None], met_wind_data=[None], met_time_data=[0]):\n",
    "    '''\n",
    "    Function that computes the new snow density at each detected accumulation\n",
    "    Args:\n",
    "        nb_iterations: number of iterations in the simulation\n",
    "        end_accumulation_times: list of ending times of accumulations in seconds since data starting date\n",
    "        start_accumulation: list of the indices of starting times of accumulations in the dataset\n",
    "        end_accumulation: list of the indices of ending times of accumulations in the dataset\n",
    "        dt: timestep between each iteration (s)\n",
    "        met_temp_data: array containing surface temperatures for each meteorological timestamp (degrees Celcius),\n",
    "                default [None], i.e. use tsfc=tsfc_default\n",
    "        met_wind_data: array containing wind speed for each meteorological timestamp (m.s^-1), default [None], i.e. use new_snow_ro=150\n",
    "        met_time_data: array containing the meteorological timestamps (s since start of simulation), default [0]\n",
    "    Returns:\n",
    "        accumulation_new_snow_ro: list containing the new snow density (kg.m^-3) corresponding to each detected accumulation\n",
    "    '''\n",
    "    \n",
    "    # Initialize new snow density\n",
    "    if met_wind_data[0] != None and float(met_wind_data[0]) > 6:\n",
    "        new_snow_ro = 250\n",
    "    else:\n",
    "        new_snow_ro = 150\n",
    "\n",
    "    # Initialize indices of next accumulation/erosion events coming up (updated when their time is past)\n",
    "    accumulation_index, wind_index = 0, 0\n",
    "    accumulation_new_snow_ro = []\n",
    "\n",
    "    for i in range(nb_iterations):\n",
    "        \n",
    "        # Update new snow density if needed\n",
    "        if wind_index<len(met_wind_data) and met_time_data[wind_index]!=None and i*dt>=met_time_data[wind_index]:\n",
    "            if met_wind_data[wind_index] != None:\n",
    "                if float(met_wind_data[wind_index]) > 6:\n",
    "                    new_snow_ro = 250\n",
    "            else:\n",
    "                new_snow_ro = 150\n",
    "            wind_index += 1\n",
    "\n",
    "        # Detection of accumulations\n",
    "        if accumulation_index<len(end_accumulation_times) and i*dt>=end_accumulation_times[accumulation_index]:     # if an accumulation was passed\n",
    "            accumulation_new_snow_ro.append(new_snow_ro)\n",
    "            accumulation_index += 1     # next accumulation that will come up\n",
    "        \n",
    "    return(accumulation_new_snow_ro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d91568-de47-46a5-9aac-1eb6bec87244",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f08bca7-4c0d-4e14-a19a-1b3b582cbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1 = xr.open_dataset('pit_5_2023.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1bc31cd-3b63-4272-807e-d546e3402684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Median filtering in space with a window [7, 7]\n",
      "---> Median filtering in time with a window of 11\n",
      "---> Summer surface defined based on scans from 2022-10-07 to 2022-10-15\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing to get clean data\n",
    "\n",
    "sp1 = sp1.ffill(dim='time')\n",
    "\n",
    "median_space_filtering(sp1, 5, x_span=7, y_span=7)\n",
    "median_time_filtering(sp1, 11)\n",
    "\n",
    "# Add the summer surface to the dataset\n",
    "\n",
    "define_summer_surface(sp1, start_summer_surface, end_summer_surface)\n",
    "\n",
    "# Redefine the zero of the dataset\n",
    "\n",
    "sp1['snow_depth'] = sp1['snow_surface'] - sp1['summer_surface']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410cf0e1-2fbc-4f09-aba2-c6d24d8d3feb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get events' timing and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ef8fc8-3b1d-4027-a066-e2cd9bf118bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dates\n",
    "\n",
    "data_starting_date_in_ns = float(sp1.time.values[0])\n",
    "\n",
    "# Define the number of iterations based on duration of the data\n",
    "\n",
    "data_starting_date_in_s = pd.to_datetime(sp1.time.values[0]).timestamp()\n",
    "data_ending_date_in_s = pd.to_datetime(sp1.time.values[-1]).timestamp()\n",
    "data_duration_in_s = data_ending_date_in_s - data_starting_date_in_s\n",
    "nb_iterations = int(data_duration_in_s/dt + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b134564a-2112-463c-a1ec-ab98275e1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sp1 = get_snow_events(sp1, x_isel, y_isel, time_window_std, std_threshold)\n",
    "\n",
    "start_accumulation = results_sp1[0]\n",
    "start_erosion = results_sp1[1]\n",
    "end_accumulation = results_sp1[2]\n",
    "end_erosion = results_sp1[3]\n",
    "\n",
    "# Convert end times into more manageable orders of magnitude\n",
    "\n",
    "end_accumulation_times = sp1.snow_depth.isel(x=x_isel, y=y_isel, time=end_accumulation)\n",
    "end_accumulation_times = (pd.to_datetime(end_accumulation_times.time).astype(int) - data_starting_date_in_ns) / 1000000000  # in s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf10733-978b-4fd3-93c1-bdf1ebc808f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get snow height for each event, convert to swe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e335d4f4-a739-4ee7-bd52-6388ecdcb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_new_snow_ro = simulate_new_snow_ro(nb_iterations, end_accumulation_times, start_accumulation, end_accumulation, dt, met_temp_data=met_temp, met_wind_data=met_wind, met_time_data=met_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c5e3458-7585-4e39-b39d-415519d76179",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_water = 1000      # in kg per m**3\n",
    "\n",
    "sp1_accumulation_heights = []\n",
    "sp1_accumulation_duration = []\n",
    "sp1_swe = []\n",
    "\n",
    "for index in range(len(start_accumulation)):\n",
    "    sp1_accumulation_heights.append(get_change_in_snow_depth(sp1, start_accumulation, end_accumulation, index, x_isel, y_isel) * 1000 / 0.01)  # in mm per m**2\n",
    "    \n",
    "    start = sp1.time.values[start_accumulation[index]]\n",
    "    end = sp1.time.values[end_accumulation[index]]\n",
    "    diff = float(end-start) / 1000000000     # in s\n",
    "    sp1_accumulation_duration.append(diff)\n",
    "    \n",
    "    ro_layer = accumulation_new_snow_ro[index]      # in kg per m**3\n",
    "    swe = sp1_accumulation_heights[index] * (ro_water/ro_layer) / sp1_accumulation_duration[index]     # in mm per s per m**2\n",
    "    sp1_swe.append(swe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178752a2-3842-44f6-95be-ab6cb226ca15",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make dataset (swe per hour) and save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb8b266-9dc6-43b9-861d-e1a934253770",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.to_datetime(sp1.time.values[0])\n",
    "end = pd.to_datetime(sp1.time.values[-1])\n",
    "nb_of_hours_in_ds = (end - start).days * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc29c81d-aa3a-4c84-a50f-cafb4bbe7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ds_sp1 = np.zeros(nb_of_hours_in_ds)\n",
    "data_start_date = start\n",
    "\n",
    "for event_index in range(len(start_accumulation)):\n",
    "    starting_time = sp1.time.values[start_accumulation[event_index]]\n",
    "    ending_time = sp1.time.values[end_accumulation[event_index]]\n",
    "    ending_time_duration = sp1.time.values[end_accumulation[event_index]+1]\n",
    "\n",
    "    starting_duration = float((starting_time-data_start_date).total_seconds()) / 3600    # in h\n",
    "    starting_index = int(starting_duration // 1)\n",
    "\n",
    "    ending_duration_true_duration = float((ending_time_duration-data_start_date).total_seconds()) / 3600    # in h\n",
    "    ending_duration = float((ending_time-data_start_date).total_seconds()) / 3600    # in h\n",
    "    ending_index = int(ending_duration // 1)\n",
    "\n",
    "    starting_swe = sp1_swe[event_index] * (starting_duration - starting_index)    # percentage of the hour during which it actually precipitated\n",
    "    ending_swe = sp1_swe[event_index] * (ending_duration_true_duration - ending_index)\n",
    "\n",
    "    data_ds_sp1[starting_index] += starting_swe\n",
    "    data_ds_sp1[ending_index] += ending_swe\n",
    "\n",
    "    for i in range(starting_index+1, ending_index):\n",
    "        data_ds_sp1[i] += sp1_swe[event_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9056989d-6381-4e3d-8ec8-eeaebeb775c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(start='2022-10-07',freq='1H',periods=nb_of_hours_in_ds)\n",
    "\n",
    "# create dataset\n",
    "ds_sp1 = xr.Dataset({\n",
    "    'swe': xr.DataArray(\n",
    "                data   = data_ds_sp1,\n",
    "                dims   = ['time'],\n",
    "                coords = {'time': times},\n",
    "                attrs  = {\n",
    "                    'units'     : 'mm/s/m**2'\n",
    "                    }\n",
    "                )\n",
    "            }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c4ee4-93c4-4d8e-8f48-7a58d92f4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_sp1.to_netcdf('snow_pit_5_precip.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a3628-675e-4a2c-84e0-e3e4e6c45922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awk",
   "language": "python",
   "name": "awk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
